{"id":"IDX-2if","title":"Blocked metadata items invisible in planner API and write flow","description":"requires_update is False whenever can_update is False. The API filters out anything not requires_update, so blocked items never make it into the items list, making blocked stats/filter behavior inaccurate. write_metadata has the same logical issue: it skips non-requires_update items before checking can_update, so the blocked_items collection is effectively dead code.\n\nReferences:\n- nfo_services.py:324 (requires_update logic)\n- app.py:545 (API filter)\n- app.py:558 (API filter)\n- app.py:1754 (write_metadata skip logic)","status":"closed","priority":2,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:19:10.501872-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:48:04.685786-05:00","closed_at":"2026-02-07T20:48:04.685786-05:00","close_reason":"Closed","labels":["metadata","nfo"]}
{"id":"IDX-4y8","title":"Known people cache not invalidated on most name changes","description":"The known people cache in app.py is only invalidated when manual video tags are added/removed, but NOT after: cluster renaming (name_cluster route), cluster merging, face deletion, or person name changes via the person detail page. Users see stale name lists until the 30-second TTL expires. All routes that modify person_name in the faces table or video_people table should call _invalidate_known_people_cache().","status":"closed","priority":1,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:08.672015-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:39:41.079049-05:00","closed_at":"2026-02-07T20:39:41.079049-05:00","close_reason":"Closed","labels":["cache"]}
{"id":"IDX-7bk","title":"Malformed XML silently recovered instead of treated as parse error","description":"_read_xml uses lxml with recover=True, so malformed NFO files can parse 'successfully' and bypass the NfoParseError logic entirely. This weakens planner safety checks that are intended to block files with parse errors from being written to. A partially corrupted NFO could be silently accepted and then overwritten with potentially incomplete data.\n\nReferences:\n- nfo_services.py:116 (recover=True parser option)\n- nfo_services.py:124 (XMLSyntaxError catch that never fires due to recovery)\n- nfo_services.py:421 (planner safety check bypassed)","status":"closed","priority":2,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:19:15.740453-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:49:17.892423-05:00","closed_at":"2026-02-07T20:49:17.892423-05:00","close_reason":"Closed","labels":["nfo"]}
{"id":"IDX-9h7","title":"Flask SECRET_KEY regenerates on every restart","description":"In config.py:67, os.urandom(24).hex() is evaluated at import time. Every time the app restarts, a new random key is generated, invalidating all existing session cookies and flash messages. Users are effectively logged out on every deployment. The fix should either require the SECRET_KEY environment variable (fail if missing), or generate once and persist to a file.","status":"closed","priority":0,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:06.076872-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:38:04.299462-05:00","closed_at":"2026-02-07T20:38:04.299462-05:00","close_reason":"Closed","labels":["config"]}
{"id":"IDX-bkg","title":"NFO concurrent write race condition across operations","description":"In nfo_services.py:979-989, if two separate NFO operations run concurrently and both write to the same shared NFO file (e.g., movie.nfo in a directory with multiple videos), the second write will overwrite the first. The runtime.written_nfos dedup set only guards within a single operation, not across operations. Consider file-level locking (fcntl.flock) or an operation-level mutex keyed by nfo_path.","status":"closed","priority":2,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:24.64105-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:47:04.173336-05:00","closed_at":"2026-02-07T20:47:04.173336-05:00","close_reason":"Closed","labels":["concurrency","nfo"]}
{"id":"IDX-c5k","title":"Manual-review sample generation does not top up to configured count","description":"The existing-sample short-circuit condition in _get_video_samples() is tautological: len(existing_paths) \u003e= min(sample_count, len(existing_paths)) is always true when existing_paths is non-empty. Effect: if only 1 sample exists but NO_FACE_SAMPLE_COUNT asks for more, generation is skipped and the video stays under-filled. Reproduced with NO_FACE_SAMPLE_COUNT=3; function returned only 1 existing sample.\n\nReferences:\n- app.py:320 (short-circuit condition)\n- app.py:324 (early return)","status":"closed","priority":2,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:19:12.542217-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:48:29.264609-05:00","closed_at":"2026-02-07T20:48:29.264609-05:00","close_reason":"Closed","labels":["manual-review"]}
{"id":"IDX-ce9","title":"Race condition in known people cache refresh","description":"In app.py:96-135, the lock is released after the staleness check (line 105) but before the expensive DB query (lines 107-115). Two concurrent requests can both decide the cache is stale and both execute the full DB query. Worse, the second thread's write at line 133 could overwrite fresher data from the first thread if timing is unlucky. The fix should either hold the lock for the entire operation or use a compare-and-swap pattern with timestamps.","status":"closed","priority":1,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:12.625866-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:40:35.879665-05:00","closed_at":"2026-02-07T20:40:35.879665-05:00","close_reason":"Closed","labels":["cache","concurrency"]}
{"id":"IDX-dtv","title":"NFO writer crashes when creating new NFO files","description":"When a video has no existing NFO file, the planner still assigns a nfo_path (the default path, nfo_services.py:380). The writer then calls write_actors() which calls _read_xml() (line 137) which tries to open(nfo_path, 'rb') - this raises OSError/NfoParseError because the file doesn't exist yet. Additionally, create_backup() (line 240) calls shutil.copy2() on the non-existent file, also crashing. New NFO file creation is completely broken.","status":"closed","priority":0,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:02.738443-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:32:31.018876-05:00","closed_at":"2026-02-07T20:32:31.018876-05:00","close_reason":"Closed","labels":["nfo"]}
{"id":"IDX-l2q","title":"SubstringInfo TypedDict mismatch between type_defs.py and text_utils.py","description":"Two incompatible definitions of SubstringInfo exist. type_defs.py:150-155 defines fields: text, count, total_length. text_utils.py:9-12 defines fields: display, count, length. The type_defs.py version is never imported anywhere. Any code that tries to use the centralized definition will break at runtime. Either remove the stale definition from type_defs.py or update it to match text_utils.py.","status":"closed","priority":1,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:15.028722-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:40:56.507698-05:00","closed_at":"2026-02-07T20:40:56.507698-05:00","close_reason":"Closed","labels":["types"]}
{"id":"IDX-mkm","title":"Noise faces retain stale cluster IDs after re-clustering","description":"In cluster_faces() (scanner.py:1998-2000), when DBSCAN classifies a face as noise (label == -1), the code simply continues, skipping the face entirely. If that face previously had a valid cluster_id from an earlier clustering run, it keeps the old cluster_id. This means noise faces silently pollute valid clusters, and the problem accumulates over time with each re-cluster. The fix should set cluster_id to -1 (or NULL) for faces that DBSCAN marks as noise.","status":"closed","priority":0,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:05.293899-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:35:41.935142-05:00","closed_at":"2026-02-07T20:35:41.935142-05:00","close_reason":"Closed","labels":["data-corruption"]}
{"id":"IDX-mu3","title":"ThreadPoolExecutor for warmup never shut down","description":"In app.py:49-55, _manual_warmup_executor (ThreadPoolExecutor) is created at module load but never has shutdown() called. On app exit, background threads may still be running, holding DB connections or writing to the filesystem. Add an atexit handler or Flask teardown to call shutdown(wait=False).","status":"closed","priority":2,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:17.277331-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:41:26.189068-05:00","closed_at":"2026-02-07T20:41:26.189068-05:00","close_reason":"Closed","labels":["resource-leak"]}
{"id":"IDX-pbt","title":"Unnecessary tojson|safe filter bypasses auto-escaping","description":"In templates/group_tagger.html:405, the existing_names variable uses tojson|safe. The |safe filter is unnecessary - Flask's tojson already produces valid JS. Removing |safe adds defense-in-depth. If existing_names ever contains user-controlled data with crafted HTML, the |safe bypasses Jinja's auto-escaping layer.","status":"closed","priority":2,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:20.042986-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:41:48.49873-05:00","closed_at":"2026-02-07T20:41:48.49873-05:00","close_reason":"Closed","labels":["security","templates"]}
{"id":"IDX-v1e","title":"EasyOCR worker process zombie risk","description":"In scanner.py:230-234 and 251-253, after calling process.terminate() + process.join(timeout=5), there is no check for process.is_alive() and no fallback to process.kill(). If the worker doesn't terminate within 5 seconds, it becomes a zombie process. The queues are also closed without join_thread(), unlike the correct pattern used at line 190 in _probe_easyocr_support(). Over time, zombie processes consume process table slots and file descriptors.","status":"closed","priority":1,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:10.86266-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:40:11.147724-05:00","closed_at":"2026-02-07T20:40:11.147724-05:00","close_reason":"Closed","labels":["ocr","resource-leak"]}
{"id":"IDX-vi5","title":"Scanner swallows DB write errors, commits partial data","description":"In write_data_to_db() (scanner.py:1573), exceptions are caught inside the 'with sqlite3.connect()' context manager. Since the exception doesn't propagate out, the context manager treats it as success and commits partial writes. If face inserts succeed but save_thumbnail() fails, you get faces in the DB with no thumbnails, or scanned_file records without their associated face data. The except block on line 1573 swallows the error, the with block exits cleanly, and sqlite3's context manager auto-commits whatever partial work was done.","status":"closed","priority":0,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:00.815425-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:28:43.365601-05:00","closed_at":"2026-02-07T20:28:43.365601-05:00","close_reason":"Closed","labels":["data-corruption"]}
{"id":"IDX-yml","title":"No transaction boundaries on multi-statement DB writes in app.py","description":"Multiple routes in app.py execute several conn.execute() calls followed by a single conn.commit(). In Python's sqlite3 module, if an exception occurs between statements, prior statements may already be auto-committed depending on isolation level, leaving the database in a partially-updated state. For example, in name_cluster a face rename could succeed but the suggestion status update could fail. Wrap related operations in explicit BEGIN/COMMIT blocks with rollback on error.","status":"closed","priority":2,"issue_type":"bug","owner":"juderajasekera@gmail.com","created_at":"2026-02-07T20:17:22.717635-05:00","created_by":"Jude Rajasekera","updated_at":"2026-02-07T20:42:38.057464-05:00","closed_at":"2026-02-07T20:42:38.057464-05:00","close_reason":"Not a bug: Python sqlite3 uses implicit transactions by default. Multiple DML statements before conn.commit() are already in the same transaction. Flask teardown rolls back on exception.","labels":["data-corruption"]}
